{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import robust_value_approx.train_value as train_value\n",
    "import robust_value_approx.utils as utils\n",
    "import plotting_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Integrator Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import double_integrator_utils\n",
    "\n",
    "vf = double_integrator_utils.get_value_function(N=5)\n",
    "\n",
    "x0_lo = -1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "x0_up = 1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [100] * vf.sys.x_dim\n",
    "\n",
    "# file options\n",
    "sys_name = 'double_int'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 16\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 1000\n",
    "train_opt.num_steps_between_sampling = 200\n",
    "train_opt.init_buffer_size = 10\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 5\n",
    "train_opt.x_adv_max_iter = 2\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 30\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertical Ball Paddle Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ball_paddle_utils\n",
    "\n",
    "vf = ball_paddle_utils.get_value_function_vertical(N=5)\n",
    "\n",
    "x0_lo = torch.Tensor([1.5, .15, -5., -1.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([2., .15, 1., 5.]).type(vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [20, 1, 20, 20]\n",
    "\n",
    "# data file options\n",
    "sys_name = 'ball_paddle_vertical'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 32\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 1000\n",
    "train_opt.num_steps_between_sampling = 200\n",
    "train_opt.init_buffer_size = 60\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 10\n",
    "train_opt.x_adv_max_iter = 3\n",
    "train_opt.x_adv_conv_tol = 1e-4\n",
    "train_opt.x_adv_lr = .25\n",
    "train_opt.batch_size = 60\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the spread of trajectories for sanity check\n",
    "fig = plotting_utils.rollout_range(vf, x0_lo, x0_up, [0, 1], [\"ball\", \"paddle\"], n=50)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Walking Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slip_utils\n",
    "\n",
    "vf, slip = slip_utils.get_value_function(torch.Tensor([6., 1.25, 0.]), N=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_lo = torch.Tensor([0, .95, 4.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([0, 1.25, 9.]).type(vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [1, 100, 100]\n",
    "\n",
    "# data file options\n",
    "sys_name = 'slip'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 64\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 1000\n",
    "train_opt.num_steps_between_sampling = 200\n",
    "train_opt.init_buffer_size = 100\n",
    "train_opt.init_num_train_steps = 1000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 5\n",
    "train_opt.x_adv_max_iter = 3\n",
    "train_opt.x_adv_conv_tol = 1e-4\n",
    "train_opt.x_adv_lr = .1\n",
    "train_opt.batch_size = 60\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the spread of trajectories for sanity check\n",
    "fig = plotting_utils.rollout_range(vf, x0_lo, x0_up, [0, 1], [\"x\", \"y\"], n=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation, v_samples_validation = vf.get_value_sample_grid(x0_lo, x0_up, num_breaks_validation, update_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x_samples_validation, x_samples_file + '_validation.pt')\n",
    "torch.save(v_samples_validation, v_samples_file + '_validation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    y = v_samples_validation.squeeze(),\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or Loading It From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation = torch.load(x_samples_file + '_validation.pt')\n",
    "v_samples_validation = torch.load(v_samples_file + '_validation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = train_value.AdversarialWithBaseline(vf, x0_lo, x0_up,\n",
    "                                          nn_width=nn_width, nn_depth=nn_depth,\n",
    "                                          x_samples_validation=x_samples_validation,\n",
    "                                          v_samples_validation=v_samples_validation)\n",
    "state_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(num_training_run):\n",
    "    adv.train(train_opt)\n",
    "    state_log.append(adv.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2D plots of sample buffers\n",
    "fig = plotting_utils.buffer_plot(state_log, x0_lo, x0_up, 1, 2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plots of adversarial samples (only integrator for now)\n",
    "fig = plotting_utils.bilevel_plot(state_log[2], adv, 0, 1, show_buffer=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training losses\n",
    "fig = plotting_utils.training_loss(state_log[0], window=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple run and plot validation validation delta\n",
    "num_runs = 5\n",
    "for run_i in range(num_runs):\n",
    "    adv = train_value.AdversarialWithBaseline(vf, x0_lo, x0_up,\n",
    "                                              nn_width=nn_width, nn_depth=nn_depth,\n",
    "                                              x_samples_validation=x_samples_validation,\n",
    "                                              v_samples_validation=v_samples_validation)\n",
    "    state_log = []\n",
    "    for _ in range(num_training_run):\n",
    "        adv.train(train_opt)\n",
    "        state_log.append(adv.get_state())\n",
    "    training_runs.append(state_log)\n",
    "    utils.update_progress((run_i + 1) / num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# improvement on test set\n",
    "fig = plotting_utils.validation_delta([s_log[-1] for s_log in training_runs])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results if needed\n",
    "now = datetime.now()\n",
    "pickle.dump(training_runs, open(\"training_runs_\" + sys_name + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + \".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load an old result\n",
    "training_runs = pickle.load(open(\"training_runs_double_int_01252020175702.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adv.baseline_model, model_file + '_baseline_model.pt')\n",
    "torch.save(adv.robust_model, model_file + '_robust_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
