{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blandry/Code/robust-value-approx/env/lib/python3.7/site-packages/ipykernel_launcher.py:14: _DrakeImportWarning:\n",
      "\n",
      "\n",
      "You may have already (directly or indirectly) imported `torch` which uses\n",
      "`RTLD_GLOBAL`. Using `RTLD_GLOBAL` may cause symbol collisions which manifest\n",
      "themselves in bugs like \"free(): invalid pointer\". Please consider importing\n",
      "`pydrake` (and related C++-wrapped libraries like `cv2`, `open3d`, etc.)\n",
      "*before* importing `torch`. For more details, see:\n",
      "https://github.com/pytorch/pytorch/issues/3059#issuecomment-534676459\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import robust_value_approx.samples_buffer as samples_buffer\n",
    "import robust_value_approx.value_approximation as value_approximation\n",
    "import robust_value_approx.training_log as training_log\n",
    "import robust_value_approx.controllers as controllers\n",
    "\n",
    "import acrobot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64\n",
    "x_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = (torch.rand((x_dim, x_dim), dtype=dtype) - .5) * 2.\n",
    "Q = .5 * Q.t()@Q\n",
    "q = (torch.rand(x_dim, dtype=dtype) - .5) * 2.\n",
    "c = (torch.rand(1, dtype=dtype) - .5) * 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blandry/Code/robust-value-approx/env/lib/python3.7/site-packages/jax/lib/xla_bridge.py:122: UserWarning:\n",
      "\n",
      "No GPU/TPU found, falling back to CPU.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vf, sys = acrobot_utils.get_value_function(25)\n",
    "Q = torch.diag(torch.tensor([1., 1., 1., 1.]))\n",
    "R = torch.diag(torch.tensor([1.]))\n",
    "x_nom = torch.tensor([np.pi, 0., 0., 0.], dtype=vf.dtype)\n",
    "u_nom = torch.zeros(vf.u_dim[0], dtype=vf.dtype)\n",
    "ctrl, S = controllers.get_lqr_controller(sys.dx, x_nom, u_nom, Q, R, vf.u_lo[0], vf.u_up[0])\n",
    "S = torch.tensor(S, dtype=vf.dtype)\n",
    "\n",
    "Q = S\n",
    "q = -2.*S@x_nom\n",
    "c = x_nom@S@x_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.rand((1000, x_dim), dtype=dtype) - .5) * 2.\n",
    "v = (torch.diag(x@Q@x.t()) + x@q + c).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88760.2143, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "scale = torch.mean(v[:,0])\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = value_approximation.QuadraticModel(vf.dtype, vf.x_dim[0], scaling=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_approx = value_approximation.InfiniteHorizonValueFunctionApproximation(dtype, x_dim, model)\n",
    "train_log = training_log.TrainingLog(1, prefix=\"quadratic\")\n",
    "samples_buff = samples_buffer.SamplesBuffer(x_dim, 1, dtype)\n",
    "samples_buff.add_samples(x, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    x_, v_ = samples_buff.get_random_samples(1000)\n",
    "    losses = vf_approx.train_step(x_, v_)\n",
    "    train_log.add_train_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0981, 0.0283, 0.0443, 0.0156],\n",
      "        [0.0283, 0.0083, 0.0128, 0.0046],\n",
      "        [0.0443, 0.0128, 0.0200, 0.0071],\n",
      "        [0.0156, 0.0046, 0.0071, 0.0025]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([[8706.5053, 2515.6380, 3932.3521, 1387.6225],\n",
      "        [2515.6380,  737.7348, 1137.9721,  404.9252],\n",
      "        [3932.3521, 1137.9721, 1776.6220,  627.4555],\n",
      "        [1387.6225,  404.9252,  627.4555,  222.8334]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[8706.5053, 2515.6380, 3932.3521, 1387.6225],\n",
      "        [2515.6380,  737.7348, 1137.9721,  404.9252],\n",
      "        [3932.3521, 1137.9721, 1776.6220,  627.4555],\n",
      "        [1387.6225,  404.9252,  627.4555,  222.8334]], dtype=torch.float64)\n",
      "---\n",
      "Parameter containing:\n",
      "tensor([-0.6163, -0.1781, -0.2784, -0.0982], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([-54704.5861, -15806.2200, -24707.6967,  -8718.6892],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([-54704.5861, -15806.2200, -24707.6967,  -8718.6892],\n",
      "       dtype=torch.float64)\n",
      "---\n",
      "Parameter containing:\n",
      "tensor([0.9681], dtype=torch.float64, requires_grad=True)\n",
      "tensor([85929.7629], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(85929.7629, dtype=torch.float64)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(vf_approx.model.Q)\n",
    "print(vf_approx.model.Q * scale)\n",
    "print(Q)\n",
    "print(\"---\")\n",
    "print(vf_approx.model.q)\n",
    "print(vf_approx.model.q * scale)\n",
    "print(q)\n",
    "print(\"---\")\n",
    "print(vf_approx.model.c)\n",
    "print(vf_approx.model.c * scale)\n",
    "print(c)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = (torch.rand((1000, x_dim), dtype=dtype) - .5) * 2.\n",
    "v_test = (torch.diag(x_test@Q@x_test.t()) + x_test@q + c).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pred = vf_approx.model(x_test).detach()\n",
    "error = v_test - v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0494e-22, dtype=torch.float64)\n",
      "tensor(3.3881e-21, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "squ_error = torch.pow(error, 2)\n",
    "print(torch.mean(squ_error))\n",
    "print(torch.max(squ_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_approx_2 = copy.deepcopy(vf_approx)\n",
    "vf_approx_2.model.Q = torch.nn.Parameter(Q / scale)\n",
    "v_pred = vf_approx_2.model(x_test).detach()\n",
    "error = v_test - v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4871e-22, dtype=torch.float64)\n",
      "tensor(7.6233e-21, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "squ_error = torch.pow(error, 2)\n",
    "print(torch.mean(squ_error))\n",
    "print(torch.max(squ_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "#     x = x[:,1],\n",
    "#     y = x[:,1],\n",
    "#     z = v[:,0],\n",
    "#     y = v[:,0],\n",
    "    y = error[:,0],\n",
    "    mode='markers',\n",
    "))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
