{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import robust_value_approx.relu_mpc as relu_mpc\n",
    "import robust_value_approx.adversarial_sample as adversarial_sample\n",
    "import robust_value_approx.utils as utils\n",
    "import plotting_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Integrator Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import double_integrator_utils\n",
    "\n",
    "N = 5\n",
    "\n",
    "# value function we benchmark the resulting control against\n",
    "vf = double_integrator_utils.get_value_function(N=N+1)\n",
    "V = vf.get_value_function()\n",
    "\n",
    "# value function used by the controller beyond one time step\n",
    "vf_next = double_integrator_utils.get_value_function(N=N)\n",
    "V_next = vf_next.get_value_function()\n",
    "\n",
    "x0_lo = -1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "x0_up = 1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "\n",
    "# file options\n",
    "sys_name = 'double_int'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertical Ball Paddle Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ball_paddle_utils\n",
    "\n",
    "N = 5\n",
    "\n",
    "# value function we benchmark the resulting control against\n",
    "vf = ball_paddle_utils.get_value_function_vertical(N=N+1)\n",
    "V = vf.get_value_function()\n",
    "\n",
    "# value function used by the controller beyond one time step\n",
    "vf_next = ball_paddle_utils.get_value_function_vertical(N=N)\n",
    "V_next = vf_next.get_value_function()\n",
    "\n",
    "x0_lo = torch.Tensor([1.5, .15, -5., -1.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([2., .15, 1., 5.]).type(vf.dtype)\n",
    "\n",
    "# data file options\n",
    "sys_name = 'ball_paddle_vertical'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slip_utils\n",
    "\n",
    "N = 3\n",
    "xf = torch.Tensor([6., 1.25, 0.])\n",
    "\n",
    "# value function we benchmark the resulting control against\n",
    "vf, slip = slip_utils.get_value_function(xf, N=N+1)\n",
    "V = vf.get_value_function()\n",
    "\n",
    "# value function used by the controller beyond one time step\n",
    "vf_next, slip_next = slip_utils.get_value_function(xf, N=N)\n",
    "V_next = vf_next.get_value_function()\n",
    "\n",
    "x0_lo = torch.Tensor([0, .95, 4.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([0, 1.25, 9.]).type(vf.dtype)\n",
    "\n",
    "# data file options\n",
    "sys_name = 'slip'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Gait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slip_utils\n",
    "\n",
    "N = 3\n",
    "xf = torch.Tensor([0., 1.2, 5])\n",
    "\n",
    "# value function we benchmark the resulting control against\n",
    "vf, slip = slip_utils.get_value_function_gait(xf, N=N+1)\n",
    "V = vf.get_value_function()\n",
    "\n",
    "# value function used by the controller beyond one time step\n",
    "vf_next, slip_next = slip_utils.get_value_function_gait(xf, N=N)\n",
    "V_next = vf_next.get_value_function()\n",
    "\n",
    "x0_lo = torch.Tensor([0, .95, 4.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([0, 1.25, 9.]).type(vf.dtype)\n",
    "\n",
    "# data file options\n",
    "sys_name = 'slipgait'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = torch.load(model_file + '_baseline_model.pt')\n",
    "robust_model = torch.load(model_file + '_robust_model.pt')\n",
    "baseline_ctrl = relu_mpc.ReLUMPC(vf, baseline_model)\n",
    "robust_ctrl = relu_mpc.ReLUMPC(vf, robust_model)\n",
    "def eval_one_step_ctrl(ctrl, x0_samp):\n",
    "    (u0, x1) = ctrl.get_ctrl(x0_samp)\n",
    "    if u0 is None:\n",
    "        return (None, None, None)\n",
    "    (x_traj_next, u_traj_next, alpha_traj_next) = vf_next.sol_to_traj(x1, *V_next(x1)[1:])\n",
    "    if x_traj_next is None:\n",
    "        return (None, None, None)\n",
    "    x_traj = torch.cat((x0_samp.unsqueeze(0).t(), x_traj_next), axis=1)\n",
    "    u_traj = torch.cat((u0.unsqueeze(0).t(), u_traj_next), axis=1)\n",
    "    # assumes no cost on alpha! (true on all benchmarks)    \n",
    "    value = vf.traj_cost(x_traj[:,1:], u_traj)\n",
    "    return (value, x_traj, u_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation = torch.load(x_samples_file + '_validation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate their Performance on Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_opt = torch.Tensor(0, 1).type(vf.dtype)\n",
    "cost_baseline = torch.Tensor(0, 1).type(vf.dtype)\n",
    "cost_robust = torch.Tensor(0, 1).type(vf.dtype)\n",
    "\n",
    "cost_opt_nl = torch.Tensor(0, 1).type(vf.dtype)\n",
    "cost_baseline_nl = torch.Tensor(0, 1).type(vf.dtype)\n",
    "cost_robust_nl = torch.Tensor(0, 1).type(vf.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "# sample_down = 10\n",
    "# num_samples = int(x_samples_validation.shape[0] / sample_down)\n",
    "for i in range(num_samples):\n",
    "    x0_samp = torch.rand(vf.sys.x_dim) * (x0_up - x0_lo) + x0_lo\n",
    "#     x0_samp = x_samples_validation[i*sample_down,:]\n",
    "\n",
    "    optimal_value, opt_s, opt_alpha = V(x0_samp)\n",
    "    if optimal_value is None:\n",
    "        print(\"opt bad\")\n",
    "        continue\n",
    "    (x_traj_opt, u_traj_opt, alpha_traj_opt) = vf.sol_to_traj(x0_samp, opt_s, opt_alpha)\n",
    "    \n",
    "    x_traj_opt_nl = slip_utils.slip_nonlinear_traj(slip, x0_samp, u_traj_opt)\n",
    "    if x_traj_opt_nl is None:\n",
    "        print(\"nl opt bad\")\n",
    "        continue\n",
    "    optimal_nl_value = vf.traj_cost(x_traj_opt_nl[:,1:], u_traj_opt)\n",
    "    \n",
    "    (baseline_value, baseline_x_traj, baseline_u_traj) = eval_one_step_ctrl(baseline_ctrl, x0_samp)\n",
    "    if baseline_value is None:\n",
    "        print(\"baseline bad\")\n",
    "        continue\n",
    "    \n",
    "    baseline_x_traj_nl = slip_utils.slip_nonlinear_traj(slip, x0_samp, baseline_u_traj)\n",
    "    if baseline_x_traj_nl is None:\n",
    "        print(\"nl baseline bad\")\n",
    "        continue\n",
    "    baseline_nl_value = vf.traj_cost(baseline_x_traj_nl[:,1:], baseline_u_traj)\n",
    "    \n",
    "    (robust_value, robust_x_traj, robust_u_traj) = eval_one_step_ctrl(robust_ctrl, x0_samp)\n",
    "    if robust_value is None:\n",
    "        print(\"robust bad\")\n",
    "        continue\n",
    "\n",
    "    robust_x_traj_nl = slip_utils.slip_nonlinear_traj(slip, x0_samp, robust_u_traj)\n",
    "    if robust_x_traj_nl is None:\n",
    "        print(\"nl robust bad\")\n",
    "        continue\n",
    "    robust_nl_value = vf.traj_cost(robust_x_traj_nl[:,1:], robust_u_traj)\n",
    "    \n",
    "    cost_opt = torch.cat((cost_opt, torch.Tensor([[optimal_value]]).type(vf.dtype)), 0)\n",
    "    cost_baseline = torch.cat((cost_baseline, torch.Tensor([[baseline_value.item()]]).type(vf.dtype)), 0)\n",
    "    cost_robust = torch.cat((cost_robust, torch.Tensor([[robust_value.item()]]).type(vf.dtype)), 0)\n",
    "    \n",
    "    cost_opt_nl = torch.cat((cost_opt_nl, torch.Tensor([[optimal_nl_value]]).type(vf.dtype)), 0)\n",
    "    cost_baseline_nl = torch.cat((cost_baseline_nl, torch.Tensor([[baseline_nl_value.item()]]).type(vf.dtype)), 0)\n",
    "    cost_robust_nl = torch.cat((cost_robust_nl, torch.Tensor([[robust_nl_value.item()]]).type(vf.dtype)), 0)\n",
    "    \n",
    "    utils.update_progress((i + 1) / num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plotting_utils.control_perf(cost_opt, cost_baseline, cost_robust, nbin=100, bartop=120, clamp_val=10000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Robust mean: \" + str(torch.mean(cost_robust - cost_opt).item()))\n",
    "print(\"Baseline mean: \" + str(torch.mean(cost_baseline - cost_opt).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting_utils.control_perf(cost_opt_nl, cost_baseline_nl, cost_robust_nl, nbin=100, bartop=120, clamp_val=100000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nonlinear Robust sub-opt mean: \" + str(torch.mean(cost_robust_nl - cost_opt_nl).item()))\n",
    "print(\"Nonlinear Baseline sub-opt mean: \" + str(torch.mean(cost_baseline_nl - cost_opt_nl).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nonlinear Robust mean: \" + str(torch.mean(cost_robust_nl).item()))\n",
    "print(\"Nonlinear Baseline mean: \" + str(torch.mean(cost_baseline_nl).item()))\n",
    "print(\"Nonlinear Optimal mean: \" + str(torch.mean(cost_opt_nl).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "pickle.dump([cost_opt, cost_baseline, cost_robust], open(\"control_perf_\" + sys_name + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + \".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "pickle.dump([cost_opt_nl, cost_baseline_nl, cost_robust_nl], open(\"control_perf_nl_\" + sys_name + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + \".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cost_opt, cost_baseline, cost_robust] = pickle.load(open(\"control_perf_slipgait_01302020161353.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cost_opt_nl, cost_baseline_nl, cost_robust_nl] = pickle.load(open(\"control_perf_nl_slipgait_01302020161353.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Gait Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "# sample_down = 100\n",
    "# num_samples = int(x_samples_validation.shape[0] / sample_down)\n",
    "for i in range(num_samples):\n",
    "    x0_samp = torch.rand(vf.sys.x_dim) * (x0_up - x0_lo) + x0_lo\n",
    "#     x0_samp = x_samples_validation[i*sample_down,:]\n",
    "\n",
    "    optimal_value, opt_s, opt_alpha = V(x0_samp)\n",
    "    if optimal_value is None:\n",
    "        print(\"opt bad\")\n",
    "        continue\n",
    "    (x_traj_opt, u_traj_opt, alpha_traj_opt) = vf.sol_to_traj(x0_samp, opt_s, opt_alpha)\n",
    "    \n",
    "    (baseline_value, baseline_x_traj, baseline_u_traj) = eval_one_step_ctrl(baseline_ctrl, x0_samp)\n",
    "    if baseline_value is None:\n",
    "        print(\"baseline bad\")\n",
    "        continue\n",
    "    \n",
    "    (robust_value, robust_x_traj, robust_u_traj) = eval_one_step_ctrl(robust_ctrl, x0_samp)\n",
    "    if robust_value is None:\n",
    "        print(\"robust bad\")\n",
    "        continue\n",
    "\n",
    "    if robust_value < baseline_value:\n",
    "        print(x0_samp)\n",
    "        print(\"Robust: \" + str(robust_value))\n",
    "        print(robust_u_traj)\n",
    "        print(robust_x_traj)\n",
    "        print(\"Baseline: \" + str(baseline_value))\n",
    "        print(baseline_u_traj)\n",
    "        print(baseline_x_traj)\n",
    "        print(\"Optimal:\" + str(optimal_value))\n",
    "        print(u_traj_opt)\n",
    "        print(x_traj_opt)\n",
    "        print(\"---\")\n",
    "        \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on nonlinear system\n",
    "# x0_samp = torch.rand(vf.sys.x_dim) * (x0_up - x0_lo) + x0_lo\n",
    "# x0_samp = torch.Tensor([0.0000, 1.0869, 6.6037]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 1.2500, 7.3988]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 1.1193, 5.2765]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 0.9500, 4.0000]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 1.2109, 7.8834]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 1.2112, 7.9895]).type(vf.dtype)\n",
    "# x0_samp = torch.Tensor([0.0000, 1.2113, 4.0963]).type(vf.dtype)                   \n",
    "x0_samp = torch.Tensor([0.0000, 1.1845, 5.1934]).type(vf.dtype) \n",
    "\n",
    "optimal_value, opt_s, opt_alpha = V(x0_samp)\n",
    "if optimal_value is None:\n",
    "    print(\"opt bad\")\n",
    "(x_traj_opt, u_traj_opt, alpha_traj_opt) = vf.sol_to_traj(x0_samp, opt_s, opt_alpha)\n",
    "print(u_traj_opt)\n",
    "\n",
    "fig = plotting_utils.slip_traj(slip, x_traj_opt[:,:-1], u_traj_opt[:,:-1], xf)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_value, baseline_x_traj, baseline_u_traj) = eval_one_step_ctrl(baseline_ctrl, x0_samp)\n",
    "if baseline_value is None:\n",
    "    print(\"baseline bad\")\n",
    "print(baseline_u_traj)\n",
    "fig = plotting_utils.slip_traj(slip, baseline_x_traj[:,:-1], baseline_u_traj[:,:-1], xf)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(robust_value, robust_x_traj, robust_u_traj) = eval_one_step_ctrl(robust_ctrl, x0_samp)\n",
    "if robust_value is None:\n",
    "    print(\"robust bad\")\n",
    "print(robust_u_traj)\n",
    "fig = plotting_utils.slip_traj(slip, robust_x_traj[:,:-1], robust_u_traj[:,:-1], xf)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"slip_baseline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cost_opt, cost_baseline, cost_robust] = pickle.load(open(\"control_perf_double_int_01252020175702.p\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
