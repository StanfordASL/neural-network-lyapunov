{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import robust_value_approx.train_value as train_value\n",
    "import robust_value_approx.utils as utils\n",
    "import plotting_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Integrator Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import double_integrator_utils\n",
    "\n",
    "vf = double_integrator_utils.get_value_function(N=5)\n",
    "\n",
    "x0_lo = -1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "x0_up = 1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [100] * vf.sys.x_dim\n",
    "\n",
    "# file options\n",
    "sys_name = 'double_int'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 16\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 1000\n",
    "train_opt.num_steps_between_sampling = 200\n",
    "train_opt.init_buffer_size = 100\n",
    "train_opt.init_num_train_steps = 1000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 20\n",
    "train_opt.x_adv_max_iter = 3\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 60\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertical Ball Paddle Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ball_paddle_utils\n",
    "\n",
    "vf = ball_paddle_utils.get_value_function_vertical(N=5)\n",
    "\n",
    "x0_lo = torch.Tensor([1.5, .15, -5., -1.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([2., .15, 1., 5.]).type(vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [20, 1, 20, 20]\n",
    "\n",
    "# data file options\n",
    "sys_name = 'ball_paddle_vertical'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 32\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 4000\n",
    "train_opt.num_steps_between_sampling = 100\n",
    "train_opt.init_buffer_size = 500\n",
    "train_opt.init_num_train_steps = 1000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 20\n",
    "train_opt.x_adv_max_iter = 2\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 150\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the spread of trajectories for sanity check\n",
    "fig = plotting_utils.rollout_range(vf, x0_lo, x0_up, [0, 1], [\"ball\", \"paddle\"], n=50)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Goal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slip_utils\n",
    "\n",
    "vf, slip = slip_utils.get_value_function(torch.Tensor([6., 1.25, 0.]), N=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_lo = torch.Tensor([0, .95, 4.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([0, 1.25, 9.]).type(vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [1, 70, 70]\n",
    "\n",
    "# data file options\n",
    "sys_name = 'slip'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 64\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 10000\n",
    "train_opt.num_steps_between_sampling = 500\n",
    "train_opt.init_buffer_size = 1000\n",
    "train_opt.init_num_train_steps = 2000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 20\n",
    "train_opt.x_adv_max_iter = 2\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 150\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the spread of trajectories for sanity check\n",
    "fig = plotting_utils.rollout_range(vf, x0_lo, x0_up, [0, 1], [\"x\", \"y\"], n=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIP Gait Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slip_utils\n",
    "\n",
    "vf, slip = slip_utils.get_value_function_gait(torch.Tensor([0., 1.2, 5]), N=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_lo = torch.Tensor([0, .95, 4.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([0, 1.25, 9.]).type(vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [1, 70, 70]\n",
    "\n",
    "# data file options\n",
    "sys_name = 'slipgait'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 64\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 3000\n",
    "train_opt.num_steps_between_sampling = 500\n",
    "train_opt.init_buffer_size = 500\n",
    "train_opt.init_num_train_steps = 1000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 20\n",
    "train_opt.x_adv_max_iter = 3\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 150\n",
    "train_opt.max_buffer_size = 1000\n",
    "\n",
    "num_training_run = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate/Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation, v_samples_validation = vf.get_value_sample_grid(x0_lo, x0_up, num_breaks_validation, update_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x_samples_validation, x_samples_file + '_validation.pt')\n",
    "torch.save(v_samples_validation, v_samples_file + '_validation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation = torch.load(x_samples_file + '_validation.pt')\n",
    "v_samples_validation = torch.load(v_samples_file + '_validation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate/Load Initial Data Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = train_value.AdversarialWithBaseline(vf, x0_lo, x0_up)\n",
    "x_samples_init, v_samples_init = adv.get_random_samples(train_opt.init_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x_samples_init, x_samples_file + '_init.pt')\n",
    "torch.save(v_samples_init, v_samples_file + '_init.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_init = torch.load(x_samples_file + '_init.pt')\n",
    "v_samples_init = torch.load(v_samples_file + '_init.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_runs = []\n",
    "baseline_models = []\n",
    "robust_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fresh_runs = 5\n",
    "for run_i in range(num_fresh_runs):\n",
    "    adv = train_value.AdversarialWithBaseline(vf, x0_lo, x0_up,\n",
    "                                              nn_width=nn_width, nn_depth=nn_depth,\n",
    "                                              x_samples_validation=x_samples_validation,\n",
    "                                              v_samples_validation=v_samples_validation,\n",
    "                                              x_samples_init=x_samples_init[:train_opt.init_buffer_size,:],\n",
    "                                              v_samples_init=v_samples_init[:train_opt.init_buffer_size,:])\n",
    "    state_log = []\n",
    "    for _ in range(num_training_run):\n",
    "        adv.train(train_opt)\n",
    "        state_log.append(adv.get_state())\n",
    "    training_runs.append(state_log)\n",
    "    baseline_models.append(copy.deepcopy(adv.baseline_model))\n",
    "    robust_models.append(copy.deepcopy(adv.robust_model))\n",
    "    utils.update_progress((run_i + 1) / num_fresh_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# improvement on test set\n",
    "# fig = plotting_utils.validation_delta([s_log[-1] for s_log in training_runs], window=50)\n",
    "i = 0\n",
    "fig = plotting_utils.validation_delta([s_log[-1] for s_log in training_runs[i:i+1]], window=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training losses\n",
    "fig = plotting_utils.training_loss(training_runs[0][-1], window=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plots of sample buffers\n",
    "fig = plotting_utils.buffer_plot(training_runs[0], x0_lo, x0_up, 1, 2, cmax=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plots of adversarial samples (only integrator for now)\n",
    "fig = plotting_utils.bilevel_plot(training_runs[0][1], adv, 0, 1, show_buffer=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "pickle.dump(training_runs, open(\"training_runs_\" + sys_name + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + \".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "for model_i in range(len(baseline_models)):\n",
    "    torch.save(baseline_models[model_i], model_file + '_baseline_model_' + str(model_i) + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + '.pt')\n",
    "    torch.save(robust_models[model_i], model_file + '_robust_model_' + str(model_i)+ \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Specific Model for Control Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i = 0\n",
    "torch.save(baseline_models[model_i], model_file + '_baseline_model.pt')\n",
    "torch.save(robust_models[model_i], model_file + '_robust_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Old Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_runs = pickle.load(open(\"training_runs_slipgait_01302020161422.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if projection is \"overfitting\" test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import double_integrator_utils\n",
    "\n",
    "vf = double_integrator_utils.get_value_function(N=5)\n",
    "\n",
    "x0_lo = -1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "x0_up = 1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [100] * vf.sys.x_dim\n",
    "\n",
    "# file options\n",
    "sys_name = 'double_int'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "# neural network options\n",
    "nn_width = 16\n",
    "nn_depth = 1\n",
    "\n",
    "# setting up adversarial training options\n",
    "train_opt = train_value.AdversarialWithBaselineTrainingOptions()\n",
    "train_opt.num_iter_desired = 1000\n",
    "train_opt.num_steps_between_sampling = 200\n",
    "train_opt.init_buffer_size = 100\n",
    "train_opt.init_num_train_steps = 1000\n",
    "train_opt.num_rand_extra = 0\n",
    "train_opt.num_x_adv_opt = 20\n",
    "train_opt.x_adv_max_iter = 3\n",
    "train_opt.x_adv_conv_tol = 1e-5\n",
    "train_opt.x_adv_lr = .2\n",
    "train_opt.batch_size = 60\n",
    "train_opt.max_buffer_size = 100000\n",
    "\n",
    "num_training_run = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_opt.num_rand_extra = 30\n",
    "train_opt.x_adv_max_iter = 2\n",
    "train_opt.baseline_use_limits = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation, v_samples_validation = vf.get_value_sample_grid(x0_lo-.1*torch.abs(x0_lo), x0_up+.1*torch.abs(x0_up), num_breaks_validation, update_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_runs = []\n",
    "baseline_models = []\n",
    "robust_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fresh_runs = 5\n",
    "for run_i in range(num_fresh_runs):\n",
    "    adv = train_value.AdversarialWithBaseline(vf, x0_lo, x0_up,\n",
    "                                              nn_width=nn_width, nn_depth=nn_depth,\n",
    "                                              x_samples_validation=x_samples_validation,\n",
    "                                              v_samples_validation=v_samples_validation)\n",
    "#                                               x_samples_init=x_samples_init[:train_opt.init_buffer_size,:],\n",
    "#                                               v_samples_init=v_samples_init[:train_opt.init_buffer_size,:])\n",
    "    state_log = []\n",
    "    for _ in range(num_training_run):\n",
    "        adv.train(train_opt)\n",
    "        state_log.append(adv.get_state())\n",
    "    training_runs.append(state_log)\n",
    "    baseline_models.append(copy.deepcopy(adv.baseline_model))\n",
    "    robust_models.append(copy.deepcopy(adv.robust_model))\n",
    "    utils.update_progress((run_i + 1) / num_fresh_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvement on test set\n",
    "fig = plotting_utils.validation_delta_overunder([s_log[-1] for s_log in training_runs], window=50)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plots of sample buffers\n",
    "fig = plotting_utils.buffer_plot(training_runs[1], x0_lo, x0_up, 0, 1, cmax=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "pickle.dump(training_runs, open(\"training_runs_overunder_\" + sys_name + \"_\" + now.strftime(\"%m%d%Y%H%M%S\") + \".p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
