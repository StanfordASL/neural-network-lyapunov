{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neural_network_lyapunov\n",
    "import neural_network_lyapunov.relu_system as relu_system\n",
    "import neural_network_lyapunov.lyapunov as lyapunov\n",
    "import neural_network_lyapunov.pybullet_data_generation as pybullet_data_generation\n",
    "import neural_network_lyapunov.dynamics_learning as dynamics_learning\n",
    "import neural_network_lyapunov.encoders as encoders\n",
    "\n",
    "import neural_network_lyapunov.test.train_2d_lyapunov_utils as train_2d_lyapunov_utils\n",
    "\n",
    "def urdf_path(file):\n",
    "    return os.path.join(os.path.dirname(neural_network_lyapunov.__file__), \"urdf\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendulum Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64\n",
    "\n",
    "# data\n",
    "world_cb = pybullet_data_generation.load_urdf_callback(urdf_path(\"pendulum.urdf\"))\n",
    "joint_space = True\n",
    "\n",
    "pybullet_x_lo = torch.tensor([-np.pi, -5.], dtype=dtype)\n",
    "pybullet_x_up = torch.tensor([np.pi, 5.], dtype=dtype)\n",
    "pybullet_noise = torch.tensor([.1, .1])\n",
    "dataset_dt = .1\n",
    "dataset_N = 5\n",
    "grayscale = True\n",
    "image_width = 48\n",
    "image_height = 48\n",
    "camera_eye_position = [0, -3, 0]\n",
    "camera_target_position = [0, 0, 0]\n",
    "camera_up_vector = [0, 0, 1]\n",
    "\n",
    "# training\n",
    "num_samples = 100\n",
    "batch_size = 60\n",
    "validation_ratio = .01\n",
    "validation_rollouts_N = 15\n",
    "validation_max_rollouts = 100\n",
    "\n",
    "dyn_learning_opt = dynamics_learning.DynamicsLearningOptions()\n",
    "\n",
    "dyn_learning_opt.dynynamics_loss_weight = 10.\n",
    "dyn_learning_opt.lyapunov_loss_at_samples_weight = 1.\n",
    "dyn_learning_opt.lyapunov_loss_weight = 1.\n",
    "dyn_learning_opt.equilibrium_loss_weight = 10.\n",
    "\n",
    "dyn_learning_opt.V_lambda = 0.01\n",
    "dyn_learning_opt.V_eps = 0.1\n",
    "\n",
    "# encoder-decoder\n",
    "encoder_class = encoders.LinearEncoder1\n",
    "decoder_class = encoders.LinearDecoder1\n",
    "use_bce = True\n",
    "use_variational = False\n",
    "z_dim = 5\n",
    "z_lo = -1. * torch.ones(z_dim, dtype=dtype)\n",
    "z_up = 1. * torch.ones(z_dim, dtype=dtype)\n",
    "\n",
    "# dynamics nn\n",
    "dyn_nn_width = 20\n",
    "dyn_nn_depth = 1\n",
    "\n",
    "# lyapunov nn\n",
    "lyap_nn_width = 20\n",
    "lyap_nn_depth = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cubes Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_falling_cubes_callback():\n",
    "    def cb(pb):\n",
    "        plane_id = pb.loadURDF(urdf_path(\"plane_white.urdf\"), flags=pb.URDF_USE_SELF_COLLISION)\n",
    "        pos = [0, 0, .25]\n",
    "        orn = pb.getQuaternionFromEuler([0, 0, 0])\n",
    "        cube1_id = pb.loadURDF(urdf_path(\"cube_blue.urdf\"), pos, orn)\n",
    "        pos = [0.03, 0, 0.025]\n",
    "        cube2_id = pb.loadURDF(urdf_path(\"cube_red.urdf\"), pos, orn)\n",
    "        pos = [-.075, 0, 0.025]\n",
    "        cube3_id = pb.loadURDF(urdf_path(\"cube_red.urdf\"), pos, orn)\n",
    "        return cube1_id\n",
    "    return cb\n",
    "\n",
    "dtype = torch.float64\n",
    "\n",
    "# data\n",
    "world_cb = load_falling_cubes_callback()\n",
    "joint_space = False\n",
    "\n",
    "pybullet_x_lo = torch.tensor([-.1, 0, .15, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=dtype)\n",
    "pybullet_x_up = torch.tensor([.1, 0, .15, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=dtype)\n",
    "pybullet_noise = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=dtype)\n",
    "dataset_dt = .05\n",
    "dataset_N = 10\n",
    "grayscale = False\n",
    "image_width = 128\n",
    "image_height = 128\n",
    "camera_eye_position = [0, -.5, .15]\n",
    "camera_target_position = [0, 0, .1]\n",
    "camera_up_vector = [0, 0, 1]\n",
    "\n",
    "# training\n",
    "num_samples = 100\n",
    "batch_size = 60\n",
    "\n",
    "validation_ratio = .01\n",
    "validation_rollouts_N = 10\n",
    "validation_max_rollouts = 10\n",
    "\n",
    "dyn_learning_opt = dynamics_learning.DynamicsLearningOptions()\n",
    "\n",
    "dyn_learning_opt.dynynamics_loss_weight = 10.\n",
    "dyn_learning_opt.lyapunov_loss_at_samples_weight = 1.\n",
    "dyn_learning_opt.lyapunov_loss_weight = 1.\n",
    "dyn_learning_opt.equilibrium_loss_weight = 10.\n",
    "\n",
    "dyn_learning_opt.V_lambda = 0.01\n",
    "dyn_learning_opt.V_eps = 0.1\n",
    "\n",
    "# encoder-decoder\n",
    "encoder_class = encoders.CNNEncoder1\n",
    "decoder_class = encoders.CNNDecoder1\n",
    "use_bce = True\n",
    "use_variational = False\n",
    "z_dim = 8\n",
    "z_lo = -1. * torch.ones(z_dim, dtype=dtype)\n",
    "z_up = 1. * torch.ones(z_dim, dtype=dtype)\n",
    "\n",
    "# dynamics nn\n",
    "dyn_nn_width = 20\n",
    "dyn_nn_depth = 1\n",
    "\n",
    "# lyapunov nn\n",
    "lyap_nn_width = 20\n",
    "lyap_nn_depth = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbsg = pybullet_data_generation.PybulletSampleGenerator(world_cb, joint_space, image_width=image_width, image_height=image_height,\n",
    "                                                        grayscale=grayscale, dtype=dtype,\n",
    "                                                        camera_eye_position=camera_eye_position,\n",
    "                                                        camera_target_position=camera_target_position,\n",
    "                                                        camera_up_vector=camera_up_vector)\n",
    "x_data, x_next_data, X_data, X_next_data = pbsg.generate_dataset(pybullet_x_lo, pybullet_x_up, dataset_dt, dataset_N, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some of the data\n",
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "pybullet_data_generation.show_sample(X_data[i,:], X_next_data[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "X_traj, x_traj = pbsg.generate_rollout(x_data[i,:], dataset_dt, 5)\n",
    "for n in range(X_traj.shape[0]):\n",
    "    pybullet_data_generation.show_sample(X_traj[n, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_ = dynamics_learning.add_noise(x_data, pybullet_noise)\n",
    "x_next_data_ = dynamics_learning.add_noise(x_next_data, pybullet_noise)\n",
    "x_train_dataloader, x_validation_dataloader = dynamics_learning.get_dataloaders(x_data_, x_next_data_, batch_size, validation_ratio)\n",
    "\n",
    "X_train_dataloader, X_validation_dataloader = dynamics_learning.get_dataloaders(X_data, X_next_data, batch_size, validation_ratio)\n",
    "\n",
    "X_rollouts, x_rollouts = dynamics_learning.dataloader_to_rollouts(pbsg, x_validation_dataloader, dataset_dt, validation_rollouts_N,\n",
    "                                                                  max_rollouts=validation_max_rollouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_nn_model = dynamics_learning.get_ff_network(dtype, z_dim, z_dim, dyn_nn_width, dyn_nn_depth)\n",
    "lyap_nn_model = dynamics_learning.get_ff_network(dtype, z_dim, 1, lyap_nn_width, lyap_nn_depth)\n",
    "\n",
    "relu_sys = relu_system.AutonomousReLUSystem(dtype, z_lo, z_up, dyn_nn_model)\n",
    "lyap = lyapunov.LyapunovDiscreteTimeHybridSystem(relu_sys, lyap_nn_model)\n",
    "\n",
    "dyn_learner = dynamics_learning.StateSpaceDynamicsLearning(x_train_dataloader, x_validation_dataloader, relu_sys, lyap, dyn_learning_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.train(10, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random rollout\n",
    "x_traj = dyn_learner.rollout(x_data[np.random.choice(x_data.shape[0], 1)[0], :], 100)\n",
    "plt.plot(x_traj)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation over rollouts\n",
    "dyn_learner.rollout_validation(x_rollouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in image space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_nn_model = dynamics_learning.get_ff_network(dtype, z_dim, z_dim, dyn_nn_width, dyn_nn_depth)\n",
    "lyap_nn_model = dynamics_learning.get_ff_network(dtype, z_dim, 1, lyap_nn_width, lyap_nn_depth)\n",
    "\n",
    "relu_sys = relu_system.AutonomousReLUSystem(dtype, z_lo, z_up, dyn_nn_model)\n",
    "lyap = lyapunov.LyapunovDiscreteTimeHybridSystem(relu_sys, lyap_nn_model)\n",
    "encoder = encoder_class(z_dim, image_width, image_height, grayscale)\n",
    "decoder = decoder_class(z_dim, image_width, image_height, grayscale)\n",
    "\n",
    "dyn_learner = dynamics_learning.LatentSpaceDynamicsLearning(X_train_dataloader, X_validation_dataloader, relu_sys, lyap, dyn_learning_opt,\n",
    "                                                            encoder, decoder, use_bce=use_bce, use_variational=use_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.train_encoder(500, validate=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dyn_learner.encoder, \"encoder\")\n",
    "torch.save(dyn_learner.decoder, \"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.encoder = torch.load(\"encoder\")\n",
    "dyn_learner.decoder = torch.load(\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dyn_learner.relu_system.dynamics_relu, \"dynamics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.relu_system.dynamics_relu = torch.load(\"dynamics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some of the data\n",
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "pybullet_data_generation.show_sample(X_data[i,:])\n",
    "X_decoded, _, _ = dyn_learner.encode_decode(X_data[i,:].unsqueeze(0))\n",
    "X_decoded = X_decoded.squeeze()\n",
    "pybullet_data_generation.show_sample(X_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.train(1000, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.lyapunov_loss_weight = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_learner.lyapunov_loss_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random rollout\n",
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "x_traj = dyn_learner.rollout(X_data[i, :], validation_rollouts_N)\n",
    "for n in range(x_traj.shape[0]):\n",
    "    pybullet_data_generation.show_sample(x_traj[n, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traj, _ = pbsg.generate_rollout(x_data[i, :], dataset_dt, validation_rollouts_N)\n",
    "for n in range(x_traj.shape[0]):\n",
    "    pybullet_data_generation.show_sample(x_traj[n, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation over rollouts\n",
    "dyn_learner.rollout_validation(X_rollouts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
