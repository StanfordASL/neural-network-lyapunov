\documentclass{article}
\usepackage{amsmath, amsfonts}
\title{An ideal non-extended formulation for leaky ReLU}
\begin{document}
\maketitle
\section{Objective}
For a leaky ReLU unit
\begin{subequations}
\begin{align}
	y = \max(c(w^Tx+b), w^Tx+b)\\
	L \le x \le U\\
	m^- \le w^Tx + b \le m^+\\
	Px \le q
\end{align}
\end{subequations}
where $0\le c < 1$, we will find an ideal non-extended formulation. Please refer to \cite{Anderson2020} for an explanation on the ideal formulation. In \cite{Anderson2020} they derived the ideal formulation for a ReLU neuron $y = \max(0, w^Tx+b)$, here we extend their approach to leaky ReLU neuron.

\section{Big-M formulation}
The big-M formulation is
\begin{subequations}
\begin{align}
	y \ge c(w^Tx+b)\\
	y \ge w^Tx+b\\
    y \le c(w^Tx+b) + (1-c)m^+\beta\\
    y \le w^Tx+b + (1-c)m^-(1-\beta)\\
    L \le x \le U\\
m^- \le w^Tx + b \le m^+\\
Px \le q
\end{align}
\end{subequations}
This formulation is not ideal, as explained in Fig 1 of \cite{Anderson2020}.

\section{Ideal extended formulation}
We consider an ideal extended formulation with new slack continuous variables
\begin{subequations}
\begin{align}
	x = x^0 + x^1\\
	y = y^0 + y^1\\
	y^0 = c(w^Tx^0 + b(1-\beta)) \le 0\\
	y^1 = w^Tx^1 + b\beta\ge 0\\
	L(1-\beta) \le x^0 \le U(1-\beta)\\
	L\beta \le x^1 \le U\beta\\
	(m^--b)(1-\beta) \le w^Tx^0\le(m^+-b)(1-\beta)\\
	(m^--b)\beta \le w^Tx^1\le(m^+-b)\beta\\
	Px^0\le q(1-\beta)\\
	Px^1\le q\beta
\end{align}
\end{subequations}
This ideal formulation is extended as it introduces new slack variables $x^0, x^1, y^0, y^1$.

\section{Ideal non-extended formulation}
To derive the ideal non-extended formulation, we want to remove the slack variables $x^0, x^1, y^0, y^1$ in the ideal extended formulation. We first write $x^1, y^0, y^1$ as function of $x, \beta, x^0$
\begin{subequations}
\begin{align}
	x^1 = x - x^0\\
	y^0 = c(w^Tx^0 + b(1-\beta))\\
	y^1 = w^Tx^1 + b\beta = w^Tx - w^Tx^0 + b\beta\\
	y = y^0 + y^1 = w^Tx - (1-c)w^Tx^0 + cb + b(1-c)\beta
\end{align}
\end{subequations}
Hence we can express $(1-c)w^1x^0_1$ as
\begin{align}
	(1-c)w_1x^0_1 = w^Tx - (1-c)\sum_{i>1}w_ix^0_i + cb  + b(1-c)\beta - y
\end{align}



\section{Appendix}
In this appendix, we try to derive the ideal non-extended formulation for ReLU unit (not the leaky ReLU) unit 
\begin{subequations}
\begin{align}
	y = \max(0, w^Tx + b)\\
	L \le x \le U
\end{align}
\end{subequations}
\subsection{big-M formulation}
We denote $m^+ = \sum_i \max(w_iL_i, w_iU_i), m^- = \sum_i \min(w_iL_i, w_iU_i)$, and get the following big-M formulation
\begin{subequations}
\begin{align}
	y \ge 0\\
	y \ge w^Tx + b\\
	y \le m^+\beta\\
	y \le w^Tx+b + m^-(1-\beta)\\
	L \le x \le U
\end{align}
\end{subequations}
\subsection{Ideal extended formulation}
Using the multiple-choice trick, we get the following ideal formulation with slack variables
\begin{subequations}
\begin{align}
	x = x^0 + x^1\\
	y = y^0 + y^1\\
	y^0 = 0 \ge w^Tx^0 + b(1-\beta)\\
	y^1 = w^Tx^1 + b\beta\ge 0\\
	L(1-\beta)\le x^0\le U(1-\beta)\\
	L\beta\le x^1\le U\beta
\end{align}
\end{subequations}

\subsection{Ideal non-extended formulation}
To derive the ideal non-extended formulation, we will need to remove the slack variable $x^0, x^1, y^0, y^1$ from the ideal extended formulation. To do so, we first remove $x^1, y^0, y^1$ as
\begin{align}
	x^1 = x - x^0\\
	y^0 = 0\\
	y^1 = w^T(x-x^0) + b\beta = y
\end{align}
Hence we have
\begin{align}
	w^Tx^0 = w^Tx + b\beta-y\\
	\Leftrightarrow w_1x^0_1 = w^Tx + b\beta -\sum_{i>1}w_ix^0_i - y\label{eq:w1x01}
\end{align}
Without loss of generality, we assume $w_i > 0\; \forall i$, hence
\begin{subequations}
\begin{align}
	w_1L_1(1-\beta)\le w_1x^0_1\le w_1U_1(1-\beta)\\
	w_1x_1 - w_1U_1\beta \le w_1x^0_1 \le w_1x_1 - w_1L_1\beta
\end{align}
\label{eq:w1x01_bounds}
\end{subequations}
Substituting $w_1x^0_1$ in the inequalities \eqref{eq:w1x01_bounds} with the right hand side of \eqref{eq:w1x01}, we get the following inequalities
\begin{subequations}
	\begin{align}
		y \ge w^Tx + b\beta - \sum_{i>1}w_ix^0_i - w_1U_1(1-\beta)\\
		y \ge \sum_{i>1}w_ix_i + b\beta - \sum_{i>1}w_ix^0_i + w_1L_1\beta\\
		y \le w^Tx + b\beta - \sum_{i>1}w_ix^0_i - w_1L_1(1-\beta)\\
		y \le \sum_{i>1}w_ix_i + b\beta - \sum_{i>1}w_ix^0_i  + w_1U_1\beta
	\end{align}
\end{subequations}
these inequalities remove the slack variable $x^0_1$.

Now we proceed to remove the slack variable $x^0_2$, we have
\begin{align}
	\begin{split}
	\max\begin{cases}
		w^Tx + b\beta -\sum_{i>2}w_ix^0_i - y - w_1U_1(1-\beta)\\
		\sum_{i>1}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i -y + w_1L_1\beta\\
		w_2L_2(1-\beta)\\
		w_2x_2 - w_2U_2\beta
	\end{cases}\\
	\le w_2x^0_2\le\\
	\min\begin{cases}
		w^Tx + b\beta - \sum_{i>2}w_ix^0_i-y - w_1L_1(1-\beta)\\
		\sum_{i>1}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i-y+w_1U_1\beta\\
		w_2U_2(1-\beta)\\
		w_2x_2-w_2L_2\beta
	\end{cases}
\end{split}
\end{align}
we get the inequalities
\begin{subequations}
\begin{align}
	y \ge w^Tx + b\beta - \sum_{i>2}w_ix^0_i - \sum_{i \le 2}w_iU_i(1-\beta)\\
	y \ge \sum_{i\neq 2}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i - w_1U_1(1-\beta) + w_2L_2\beta\\
	y \ge \sum_{i>1}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i + w_1L_1\beta - w_2U_2(1-\beta)\\
	y \ge \sum_{i>2}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i  + \sum_{i\le 2}w_iL_i\beta\\
	y \le w^Tx + b + b\beta - \sum_{i>2}w_ix^0_i - \sum_{i\le 2}w_iL_i(1-\beta)\\
	y \le \sum_{i>1}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i  + w_1U_1\beta - w_2L_2(1-\beta)\\
	y \le \sum_{i\neq 2}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i - w_1L_1(1-\beta) + w_2U_2\beta\\
	y \le \sum_{i > 2}w_ix_i + b\beta - \sum_{i>2}w_ix^0_i + \sum_{i\le 2}w_iU_i\beta
\end{align}
\end{subequations}
If we follow this procedure to remove the remaining slack variables, we end up with the inequalities
\begin{subequations}
	\begin{align}
		y \ge \sum_{i\in\mathcal{I}}w_ix_i + b\beta - \sum_{i\in\mathcal{I}}w_iU_i(1-\beta) + \sum_{i\notin\mathcal{I}}w_iL_i\beta\\
		y \le \sum_{i\in\mathcal{I}}w_ix_i + b\beta - \sum_{i\in\mathcal{I}}w_iL_i(1-\beta) + \sum_{i\notin\mathcal{I}}w_iU_i\beta
	\end{align}
\end{subequations}
where $I$ is a subset of the set $\{1, 2, \hdots, n\}$.



\begin{thebibliography}{9}
	\bibitem{Anderson2020}
	Ross Anderson, Joey Huchette, Christian Tjandraatmadja and Juan Pablo Vielma \textit{Strong mixed-integer programming formulations for trained neural networks}, Mathematical Programming, 2020
\end{thebibliography}
\end{document}
