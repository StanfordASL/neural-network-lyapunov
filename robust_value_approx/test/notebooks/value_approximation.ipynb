{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blandry/Code/robust-value-approx/robust_value_approx/test/slip_utils.py:1: _DrakeImportWarning:\n",
      "\n",
      "\n",
      "You may have already (directly or indirectly) imported `torch` which uses\n",
      "`RTLD_GLOBAL`. Using `RTLD_GLOBAL` may cause symbol collisions which manifest\n",
      "themselves in bugs like \"free(): invalid pointer\". Please consider importing\n",
      "`pydrake` (and related C++-wrapped libraries like `cv2`, `open3d`, etc.)\n",
      "*before* importing `torch`. For more details, see:\n",
      "https://github.com/pytorch/pytorch/issues/3059#issuecomment-534676459\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotting_utils\n",
    "\n",
    "import robust_value_approx.samples_generator as samples_generator\n",
    "import robust_value_approx.samples_buffer as samples_buffer\n",
    "import robust_value_approx.value_approximation as value_approximation\n",
    "import robust_value_approx.training_log as training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import double_integrator_utils\n",
    "\n",
    "vf = double_integrator_utils.get_value_function(N=5)\n",
    "x0_lo = -1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "x0_up = 1 * torch.ones(vf.sys.x_dim, dtype=vf.dtype)\n",
    "\n",
    "# validation options\n",
    "num_breaks_validation = [100] * vf.sys.x_dim\n",
    "\n",
    "# file options\n",
    "sys_name = 'double_int'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "opt = dict(\n",
    "    max_buffer_size = None,\n",
    "    init_num_samples = 100,\n",
    "    init_num_trainig_step = 100,\n",
    "    num_generations = 50,\n",
    "    num_samples_per_generation = 10,\n",
    "    num_train_step_per_gen = 100,\n",
    "    batch_size = 30,\n",
    "    nn_width = 32,\n",
    "    nn_depth = 1,\n",
    "    num_samples_validation = 5000,\n",
    "    adv_max_iter = 3,\n",
    "    adv_conv_tol = 1e-5,\n",
    "    adv_learning_rate = .25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_buff = samples_buffer.SamplesBuffer(vf.sys.x_dim*(vf.N-1), vf.N-1, vf.dtype, max_size=opt['max_buffer_size'])\n",
    "samples_gen = samples_generator.RandomSampleGenerator(vf, x0_lo, x0_up)\n",
    "vf_approx = value_approximation.FiniteHorizonValueFunctionApproximation(vf, x0_lo, x0_up, opt['nn_width'], opt['nn_depth'])\n",
    "train_log = training_log.TrainingLog(vf.N-1, prefix=\"baseline\", first_value_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation, v_labels_validation = samples_gen.generate_samples(opt['num_samples_validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_samples, v_labels) = samples_gen.generate_samples(opt['init_num_samples'])\n",
    "samples_buff.add_samples(x_samples, v_labels)\n",
    "for train_step_i in range(opt['init_num_trainig_step']):\n",
    "    x, v = samples_buff.get_random_samples(opt['batch_size'])\n",
    "    losses = vf_approx.train_step(x, v)\n",
    "    train_log.add_train_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_buff_adv = copy.deepcopy(samples_buff)\n",
    "samples_gen_adv = samples_generator.MIPAdversarialSampleGenerator(vf, x0_lo, x0_up, \n",
    "                                                                  max_iter=opt['adv_max_iter'],\n",
    "                                                                  conv_tol=opt['adv_conv_tol'],\n",
    "                                                                  learning_rate=opt['adv_learning_rate'])\n",
    "vf_approx_adv = copy.deepcopy(vf_approx)\n",
    "train_log_adv = training_log.TrainingLog.get_copy(\n",
    "    train_log, prefix=\"adversarial\", keep_writer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = vf_approx_adv.validation_loss(x_samples_validation, v_labels_validation)\n",
    "train_log_adv.add_validation_loss(validation_losses)\n",
    "validation_losses = vf_approx.validation_loss(x_samples_validation, v_labels_validation)\n",
    "train_log.add_validation_loss(validation_losses)\n",
    "for gen_i in range(opt['num_generations']):\n",
    "    # adverserial samples\n",
    "    (x_samples, v_labels) = samples_gen_adv.generate_samples(opt['num_samples_per_generation'], vf_approx_adv)\n",
    "    samples_buff_adv.add_samples(x_samples, v_labels)\n",
    "    # random samples\n",
    "    (x_samples, v_labels) = samples_gen.generate_samples(opt['num_samples_per_generation'])\n",
    "    samples_buff.add_samples(x_samples, v_labels)\n",
    "    for train_step_i in range(opt['num_train_step_per_gen']):\n",
    "        samples_indices = samples_buff_adv.get_random_sample_indices(opt['batch_size'])\n",
    "        x, v = samples_buff_adv.get_samples_from_indices(samples_indices)\n",
    "        losses = vf_approx_adv.train_step(x, v)\n",
    "        train_log_adv.add_train_loss(losses)\n",
    "        x, v = samples_buff.get_samples_from_indices(samples_indices)\n",
    "        losses = vf_approx.train_step(x, v)\n",
    "        train_log.add_train_loss(losses)\n",
    "    validation_losses = vf_approx_adv.validation_loss(x_samples_validation, v_labels_validation)\n",
    "    train_log_adv.add_validation_loss(validation_losses)\n",
    "    validation_losses = vf_approx.validation_loss(x_samples_validation, v_labels_validation)\n",
    "    train_log.add_validation_loss(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acrobot_utils\n",
    "\n",
    "vf = acrobot_utils.get_value_function(N=5)\n",
    "x_dim = 4\n",
    "x0_lo = torch.Tensor([-np.pi, -np.pi, -10., -10.]).type(vf.dtype)\n",
    "x0_up = torch.Tensor([np.pi, np.pi, 10., 10.]).type(vf.dtype)\n",
    "\n",
    "# file options\n",
    "sys_name = 'acrobot'\n",
    "x_samples_file = '../data/learn_value_function_' + sys_name + '_x'\n",
    "v_samples_file = '../data/learn_value_function_' + sys_name + '_v'\n",
    "model_file = '../data/' + sys_name\n",
    "\n",
    "opt = dict(\n",
    "    max_buffer_size = None,\n",
    "    init_num_samples = 100,\n",
    "    init_num_trainig_step = 1000,\n",
    "    num_generations = 50,\n",
    "    num_samples_per_generation = 10,\n",
    "    num_train_step_per_gen = 100,\n",
    "    batch_size = 30,\n",
    "    nn_width = 32,\n",
    "    nn_depth = 1,\n",
    "    num_samples_validation = 100,\n",
    "    adv_max_iter = 3,\n",
    "    adv_conv_tol = 1e-5,\n",
    "    adv_learning_rate = .25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_buff = samples_buffer.SamplesBuffer(x_dim*(vf.N-1), vf.N-1, vf.dtype, max_size=opt['max_buffer_size'])\n",
    "samples_gen = samples_generator.RandomSampleGenerator(vf, x0_lo, x0_up)\n",
    "vf_approx = value_approximation.FiniteHorizonValueFunctionApproximation(vf, x0_lo, x0_up, opt['nn_width'], opt['nn_depth'])\n",
    "train_log = training_log.TrainingLog(vf.N-1, prefix=\"baseline\", first_value_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_validation, v_labels_validation = samples_gen.generate_samples(opt['num_samples_validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_samples, v_labels) = samples_gen.generate_samples(opt['init_num_samples'])\n",
    "samples_buff.add_samples(x_samples, v_labels)\n",
    "for train_step_i in range(opt['init_num_trainig_step']):\n",
    "    x, v = samples_buff.get_random_samples(opt['batch_size'])\n",
    "    losses = vf_approx.train_step(x, v)\n",
    "    train_log.add_train_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_buff_adv = copy.deepcopy(samples_buff)\n",
    "samples_gen_adv = samples_generator.NLPAdversarialSampleGenerator(vf, x0_lo, x0_up, \n",
    "                                                                  max_iter=opt['adv_max_iter'],\n",
    "                                                                  conv_tol=opt['adv_conv_tol'],\n",
    "                                                                  learning_rate=opt['adv_learning_rate'])\n",
    "vf_approx_adv = copy.deepcopy(vf_approx)\n",
    "train_log_adv = training_log.TrainingLog.get_copy(\n",
    "    train_log, prefix=\"adversarial\", keep_writer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = vf_approx_adv.validation_loss(x_samples_validation, v_labels_validation)\n",
    "train_log_adv.add_validation_loss(validation_losses)\n",
    "validation_losses = vf_approx.validation_loss(x_samples_validation, v_labels_validation)\n",
    "train_log.add_validation_loss(validation_losses)\n",
    "for gen_i in range(opt['num_generations']):\n",
    "    # adverserial samples\n",
    "    (x_samples, v_labels) = samples_gen_adv.generate_samples(opt['num_samples_per_generation'], vf_approx_adv)\n",
    "    samples_buff_adv.add_samples(x_samples, v_labels)\n",
    "    # random samples\n",
    "    (x_samples, v_labels) = samples_gen.generate_samples(opt['num_samples_per_generation'])\n",
    "    samples_buff.add_samples(x_samples, v_labels)\n",
    "    for train_step_i in range(opt['num_train_step_per_gen']):\n",
    "        samples_indices = samples_buff_adv.get_random_sample_indices(opt['batch_size'])\n",
    "        x, v = samples_buff_adv.get_samples_from_indices(samples_indices)\n",
    "        losses = vf_approx_adv.train_step(x, v)\n",
    "        train_log_adv.add_train_loss(losses)\n",
    "        x, v = samples_buff.get_samples_from_indices(samples_indices)\n",
    "        losses = vf_approx.train_step(x, v)\n",
    "        train_log.add_train_loss(losses)\n",
    "    validation_losses = vf_approx_adv.validation_loss(x_samples_validation, v_labels_validation)\n",
    "    train_log_adv.add_validation_loss(validation_losses)\n",
    "    validation_losses = vf_approx.validation_loss(x_samples_validation, v_labels_validation)\n",
    "    train_log.add_validation_loss(validation_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
