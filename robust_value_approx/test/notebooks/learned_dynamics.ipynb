{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import gurobipy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import robust_value_approx.relu_system as relu_system\n",
    "import robust_value_approx.lyapunov as lyapunov\n",
    "import robust_value_approx.pybullet_data as pybullet_data\n",
    "\n",
    "import robust_value_approx.test.train_2d_lyapunov_utils as train_2d_lyapunov_utils\n",
    "import robust_value_approx.latent_system as latent_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "urdf = 'pendulum.urdf'\n",
    "dtype = torch.float64\n",
    "pybullet_x_lo = torch.tensor([-np.pi/2, -5.], dtype=dtype)\n",
    "pybullet_x_up = torch.tensor([np.pi/2, 5.], dtype=dtype)\n",
    "dt = .1\n",
    "grayscale = True\n",
    "image_width = 48\n",
    "image_height = 48\n",
    "\n",
    "# training\n",
    "num_samples = 1000\n",
    "validation_ratio = .01\n",
    "batch_size = 20\n",
    "dyn_loss_weight = 1.\n",
    "lyap_loss_weight = 1.\n",
    "\n",
    "# encoder-decoder\n",
    "use_conv = False\n",
    "use_bce = True\n",
    "use_variational = False\n",
    "z_dim = 3\n",
    "z_lo = -1. * torch.ones(z_dim, dtype=dtype)\n",
    "z_up = 1. * torch.ones(z_dim, dtype=dtype)\n",
    "\n",
    "# dynamics nn\n",
    "dyn_nn_width = 5\n",
    "dyn_nn_depth = 1\n",
    "\n",
    "# lyapunov nn\n",
    "lyap_nn_width = 5\n",
    "lyap_nn_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbsg = pybullet_data.PybulletSampleGenerator(urdf, image_width=image_width, image_height=image_height, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, x_next_data, X_data, X_next_data = pbsg.generate_dataset(pybullet_x_lo, pybullet_x_up, dt, num_samples, grayscale=grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "pybullet_data.show_sample(X_data[i,:], X_next_data[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_nn_layers = [torch.nn.Linear(z_dim, dyn_nn_width), torch.nn.ReLU()]\n",
    "for i in range(dyn_nn_depth):\n",
    "    dyn_nn_layers += [torch.nn.Linear(dyn_nn_width, dyn_nn_width), torch.nn.ReLU()]\n",
    "dyn_nn_layers += [torch.nn.Linear(dyn_nn_width, z_dim)]\n",
    "dyn_nn_model = torch.nn.Sequential(*dyn_nn_layers).type(dtype)\n",
    "\n",
    "lyap_nn_layers = [torch.nn.Linear(z_dim, lyap_nn_width), torch.nn.ReLU()]\n",
    "for i in range(lyap_nn_depth):\n",
    "    lyap_nn_layers += [torch.nn.Linear(lyap_nn_width, lyap_nn_width), torch.nn.ReLU()]\n",
    "lyap_nn_layers += [torch.nn.Linear(lyap_nn_width, 1)]\n",
    "lyap_nn_model = torch.nn.Sequential(*lyap_nn_layers).type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in image space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = TensorDataset(X_data.double(), X_next_data.double())\n",
    "# X_dataset = TensorDataset(X_data[:5,:].double(), X_next_data[:5,:].double())\n",
    "\n",
    "train_size = int((1. - validation_ratio) * len(X_dataset))\n",
    "test_size = len(X_dataset) - train_size\n",
    "train_dataset_img, validation_dataset_img = torch.utils.data.random_split(X_dataset, [train_size, test_size])\n",
    "train_dataloader_img = DataLoader(\n",
    "    train_dataset_img,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "validation_dataloader_img = DataLoader(\n",
    "    validation_dataset_img,\n",
    "    batch_size=len(validation_dataset_img),\n",
    ")\n",
    "validation_data_img = validation_dataloader_img.__iter__().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_sys = relu_system.AutonomousReLUSystem(dtype, z_lo, z_up, dyn_nn_model)\n",
    "lyap = lyapunov.LyapunovDiscreteTimeHybridSystem(relu_sys, lyap_nn_model)\n",
    "latent_sys = latent_system.LatentAutonomousReLUSystem(relu_sys, lyap, use_conv=use_conv, use_bce=use_bce, use_variational=use_variational,\n",
    "                                                      image_width=image_width, image_height=image_height, grayscale=grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(X_data.shape[0], 1)[0]\n",
    "x_traj = latent_sys.rollout(X_data[i, :], 5, clamp=True)\n",
    "for n in range(x_traj.shape[0]):\n",
    "    pybullet_data.show_sample(x_traj[n, :], clamp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for 2D latent systems only)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "train_2d_lyapunov_utils.plot_lyapunov(ax, latent_sys.lyapunov.lyapunov_relu,\n",
    "                                      latent_sys.V_lambda, latent_sys.z_equilibrium,\n",
    "                                      latent_sys.z_lo, latent_sys.z_up, [10, 10], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': latent_sys.encoder.parameters()},\n",
    "                              {'params': latent_sys.decoder.parameters()},\n",
    "                              {'params': latent_sys.lyapunov.lyapunov_relu.parameters()}])\n",
    "\n",
    "writer = SummaryWriter()\n",
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in range(1000):\n",
    "    for x, x_next in train_dataloader_img:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if dyn_loss_weight > 0:\n",
    "            x_decoded, x_next_pred_decoded, z_mu, z_log_var = latent_sys.vae_forward(x)\n",
    "            dyn_loss = latent_sys.vae_loss(x, x_next, x_decoded, x_next_pred_decoded, z_mu, z_log_var)\n",
    "        else:\n",
    "            dyn_loss = torch.tensor(0., dtype=latent_sys.dtype)\n",
    "        \n",
    "        if lyap_loss_weight > 0:\n",
    "            lyap_loss = latent_sys.lyapunov_loss()\n",
    "        else:\n",
    "            lyap_loss = torch.tensor(0., dtype=latent_sys.dtype)\n",
    "        \n",
    "        loss = dyn_loss_weight * dyn_loss + lyap_loss_weight * lyap_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Dynamics/train', dyn_loss_weight * dyn_loss.item(), n_iter)\n",
    "        writer.add_scalar('Lyapunov', lyap_loss_weight * lyap_loss.item(), n_iter)\n",
    "        n_iter += 1\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        x_decoded, x_next_pred_decoded, z_mu, z_log_var = latent_sys.vae_forward(validation_data_img[0])\n",
    "        validation_loss = latent_sys.vae_loss(validation_data_img[0], validation_data_img[1], x_decoded, x_next_pred_decoded, z_mu, z_log_var)\n",
    "        writer.add_scalar('Dynamics/validation', validation_loss.item(), n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = TensorDataset(x_data, x_next_data)\n",
    "train_size = int((1. - validation_ratio) * len(x_dataset))\n",
    "test_size = len(x_dataset) - train_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(x_dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=len(validation_dataset),\n",
    ")\n",
    "validation_data = validation_dataloader.__iter__().next()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
